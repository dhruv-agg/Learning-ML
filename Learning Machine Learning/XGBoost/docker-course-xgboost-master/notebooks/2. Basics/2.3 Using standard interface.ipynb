{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"width:100%\" src=\"../images/practical_xgboost_in_python_notebook_header.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using standard interface\n",
    "The following notebooks presents the basic usage of native XGBoost Python interface.\n",
    "\n",
    "**Flight-plan**:\n",
    "- <a href=\"#libs\">load libraries</a> and <a href=\"#data\">prepare data</a>,\n",
    "- <a href=\"#params\">specify parameters</a>,\n",
    "- <a href=\"#train\">train classifier</a>,\n",
    "- <a href=\"#predict\">make predictions</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading libraries<a name='libs' />\n",
    "Begin with loading all required libraries in one place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data<a name='data' />\n",
    "We are going to use bundled [Agaricus](https://archive.ics.uci.edu/ml/datasets/Mushroom) dataset which can be downloaded [here](https://github.com/dmlc/xgboost/tree/master/demo/data).\n",
    "\n",
    "> This data set records biological attributes of different mushroom species, and the target is to predict whether it is poisonous\n",
    "\n",
    "> This data set includes descriptions of hypothetical samples corresponding to 23 species of gilled mushrooms in the Agaricus and Lepiota Family. Each species is identified as definitely edible, definitely poisonous, or of unknown edibility and not recommended. This latter class was combined with the poisonous one. The Guide clearly states that there is no simple rule for determining the edibility of a mushroom;\n",
    "\n",
    "It consist of 8124 instances, characterized by 22 attributes (both numeric and categorical). The target class is either 0 or 1 which means binary classification problem.\n",
    "\n",
    "> **Important**: XGBoost handles only numeric variables.\n",
    "\n",
    "Lucily all the data have alreay been pre-process for us. Categorical variables have been encoded, and all instances divided into train and test datasets. You will know how to do this on your own in later lectures.\n",
    "\n",
    "Data needs to be stored in `DMatrix` object which is designed to handle sparse datasets. It can be populated in couple ways:\n",
    "- using libsvm format txt file,\n",
    "- using Numpy 2D array (most popular),\n",
    "- using XGBoost binary buffer file\n",
    "\n",
    "In this case we'll use first option.\n",
    "\n",
    "> Libsvm files stores only non-zero elements in format \n",
    "> \n",
    "> `<label> <feature_a>:<value_a> <feature_c>:<value_c> ... <feature_z>:<value_z>`\n",
    ">\n",
    "> Any missing features indicate that it's corresponding value is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix('../data/agaricus.txt.train')\n",
    "dtest = xgb.DMatrix('../data/agaricus.txt.test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine what was loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset contains 6513 rows and 127 columns\n",
      "Test dataset contains 1611 rows and 127 columns\n"
     ]
    }
   ],
   "source": [
    "print(\"Train dataset contains {0} rows and {1} columns\".format(dtrain.num_row(), dtrain.num_col()))\n",
    "print(\"Test dataset contains {0} rows and {1} columns\".format(dtest.num_row(), dtest.num_col()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train possible labels: \n",
      "[ 0.  1.]\n",
      "\n",
      "Test possible labels: \n",
      "[ 0.  1.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Train possible labels: \")\n",
    "print(np.unique(dtrain.get_label()))\n",
    "\n",
    "print(\"\\nTest possible labels: \")\n",
    "print(np.unique(dtest.get_label()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify training parameters<a name='params' />\n",
    "Let's make the following assuptions and adjust algorithm parameters to it:\n",
    "- we are dealing with binary classification problem (`'objective':'binary:logistic'`),\n",
    "- we want shallow single trees with no more than 2 levels (`'max_depth':2`),\n",
    "- we don't any oupout (`'silent':1`),\n",
    "- we want algorithm to learn fast and aggressively (`'eta':1`),\n",
    "- we want to iterate only 5 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective':'binary:logistic',\n",
    "    'max_depth':2,\n",
    "    'silent':1,\n",
    "    'eta':1\n",
    "}\n",
    "\n",
    "num_rounds = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training classifier<a name='train' />\n",
    "To train the classifier we simply pass to it a training dataset, parameters list and information about number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = xgb.train(params, dtrain, num_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also observe performance on test dataset using `watchlist`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttest-error:0.042831\ttrain-error:0.046522\n",
      "[1]\ttest-error:0.021726\ttrain-error:0.022263\n",
      "[2]\ttest-error:0.006207\ttrain-error:0.007063\n",
      "[3]\ttest-error:0.018001\ttrain-error:0.0152\n",
      "[4]\ttest-error:0.006207\ttrain-error:0.007063\n"
     ]
    }
   ],
   "source": [
    "watchlist  = [(dtest,'test'), (dtrain,'train')] # native interface only\n",
    "bst = xgb.train(params, dtrain, num_rounds, watchlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions<a name='predict' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.08073306,  0.92217326,  0.08073306, ...,  0.98059034,\n",
       "        0.01182149,  0.98059034], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_prob = bst.predict(dtest)\n",
    "preds_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate simple accuracy metric to verify the results. Of course validation should be performed accordingly to the dataset, but in this case accuracy is sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted correctly: 1601/1611\n",
      "Error: 0.0062\n"
     ]
    }
   ],
   "source": [
    "labels = dtest.get_label()\n",
    "preds = preds_prob > 0.5 # threshold\n",
    "correct = 0\n",
    "\n",
    "for i in range(len(preds)):\n",
    "    if (labels[i] == preds[i]):\n",
    "        correct += 1\n",
    "\n",
    "print('Predicted correctly: {0}/{1}'.format(correct, len(preds)))\n",
    "print('Error: {0:.4f}'.format(1-correct/len(preds)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
