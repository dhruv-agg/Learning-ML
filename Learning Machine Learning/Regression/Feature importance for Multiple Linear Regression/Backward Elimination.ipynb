{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Select significance level\n",
    "- Fit our model with all possible independent variables.\n",
    "- Consider variable with highest p-value.\n",
    "- If p-value is greater than significance level, remove variable\n",
    "- Again fit the model without removed variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward Elimination For Multiple Linear Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhruv.aggarwal\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Multiple Linear Regression\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('salary matrix.csv')\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, 4].values\n",
    "\n",
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "X[:, 0] = labelencoder.fit_transform(X[:, 0])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [0])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "\n",
    "# Avoiding the Dummy Variable Trap\n",
    "X = X[:, 1:]\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1/3, random_state = 0)\n",
    "\n",
    "# Fitting Multiple Linear Regression to the Training set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as we know in multiple linear regression,\n",
    "\n",
    "$ y = b0+b1X1+b2X2+b3X3+….+bnXn $\n",
    "\n",
    "we can also represent it as\n",
    "\n",
    "$ y = b0X0+b1X1+b2X2+b3X3+….+bnXn $\n",
    "where $ X0 = 1 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can add one column with all values as 1 to represent $ b0X0 $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sm\n",
    "X = np.append ( arr = np.ones([30,1]).astype(int), values = X, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is done because statsmodels library requires it to be done for constants.\n",
    "\n",
    "Now, according to backward elimination for multiple linear regression algorithm, let us fit all variables in our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.961</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.952</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   117.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 03 Mar 2019</td> <th>  Prob (F-statistic):</th> <td>4.71e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:09:30</td>     <th>  Log-Likelihood:    </th> <td> -300.09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    30</td>      <th>  AIC:               </th> <td>   612.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    24</td>      <th>  BIC:               </th> <td>   620.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 2.146e+04</td> <td> 4689.376</td> <td>    4.576</td> <td> 0.000</td> <td> 1.18e+04</td> <td> 3.11e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>-1421.4255</td> <td> 2683.353</td> <td>   -0.530</td> <td> 0.601</td> <td>-6959.595</td> <td> 4116.744</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   92.8656</td> <td> 2735.524</td> <td>    0.034</td> <td> 0.973</td> <td>-5552.978</td> <td> 5738.710</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    3.3361</td> <td>    2.410</td> <td>    1.384</td> <td> 0.179</td> <td>   -1.637</td> <td>    8.310</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td> -423.7607</td> <td> 1282.271</td> <td>   -0.330</td> <td> 0.744</td> <td>-3070.237</td> <td> 2222.716</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td> 9437.2530</td> <td>  510.978</td> <td>   18.469</td> <td> 0.000</td> <td> 8382.645</td> <td> 1.05e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.020</td> <th>  Durbin-Watson:     </th> <td>   1.918</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.364</td> <th>  Jarque-Bera (JB):  </th> <td>   1.629</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.414</td> <th>  Prob(JB):          </th> <td>   0.443</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.214</td> <th>  Cond. No.          </th> <td>8.00e+03</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.961\n",
       "Model:                            OLS   Adj. R-squared:                  0.952\n",
       "Method:                 Least Squares   F-statistic:                     117.2\n",
       "Date:                Sun, 03 Mar 2019   Prob (F-statistic):           4.71e-16\n",
       "Time:                        16:09:30   Log-Likelihood:                -300.09\n",
       "No. Observations:                  30   AIC:                             612.2\n",
       "Df Residuals:                      24   BIC:                             620.6\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       2.146e+04   4689.376      4.576      0.000    1.18e+04    3.11e+04\n",
       "x1         -1421.4255   2683.353     -0.530      0.601   -6959.595    4116.744\n",
       "x2            92.8656   2735.524      0.034      0.973   -5552.978    5738.710\n",
       "x3             3.3361      2.410      1.384      0.179      -1.637       8.310\n",
       "x4          -423.7607   1282.271     -0.330      0.744   -3070.237    2222.716\n",
       "x5          9437.2530    510.978     18.469      0.000    8382.645    1.05e+04\n",
       "==============================================================================\n",
       "Omnibus:                        2.020   Durbin-Watson:                   1.918\n",
       "Prob(Omnibus):                  0.364   Jarque-Bera (JB):                1.629\n",
       "Skew:                           0.414   Prob(JB):                        0.443\n",
       "Kurtosis:                       2.214   Cond. No.                     8.00e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large,  8e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = X[:,[0,1,2,3,4,5]]\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now  we have to remove 2nd column i.e. x2 because its p-value is maximum i.e. 0.973 ,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.000e+00, 0.000e+00, 2.300e+03, 0.000e+00, 1.100e+00],\n",
       "       [1.000e+00, 1.000e+00, 2.100e+03, 1.000e+00, 1.300e+00],\n",
       "       [1.000e+00, 0.000e+00, 2.104e+03, 2.000e+00, 1.500e+00],\n",
       "       [1.000e+00, 0.000e+00, 1.200e+03, 1.000e+00, 2.000e+00],\n",
       "       [1.000e+00, 1.000e+00, 1.254e+03, 2.000e+00, 2.200e+00],\n",
       "       [1.000e+00, 0.000e+00, 1.236e+03, 1.000e+00, 2.900e+00],\n",
       "       [1.000e+00, 0.000e+00, 1.452e+03, 2.000e+00, 3.000e+00],\n",
       "       [1.000e+00, 1.000e+00, 1.789e+03, 1.000e+00, 3.200e+00],\n",
       "       [1.000e+00, 0.000e+00, 1.645e+03, 1.000e+00, 3.200e+00],\n",
       "       [1.000e+00, 0.000e+00, 1.258e+03, 0.000e+00, 3.700e+00],\n",
       "       [1.000e+00, 1.000e+00, 1.478e+03, 3.000e+00, 3.900e+00],\n",
       "       [1.000e+00, 0.000e+00, 1.257e+03, 2.000e+00, 4.000e+00],\n",
       "       [1.000e+00, 0.000e+00, 1.596e+03, 1.000e+00, 4.000e+00],\n",
       "       [1.000e+00, 1.000e+00, 1.256e+03, 2.000e+00, 4.100e+00],\n",
       "       [1.000e+00, 0.000e+00, 1.489e+03, 3.000e+00, 4.500e+00],\n",
       "       [1.000e+00, 0.000e+00, 1.236e+03, 3.000e+00, 4.900e+00],\n",
       "       [1.000e+00, 1.000e+00, 2.311e+03, 2.000e+00, 5.100e+00],\n",
       "       [1.000e+00, 0.000e+00, 2.245e+03, 3.000e+00, 5.300e+00],\n",
       "       [1.000e+00, 0.000e+00, 2.365e+03, 1.000e+00, 5.900e+00],\n",
       "       [1.000e+00, 0.000e+00, 1.500e+03, 3.000e+00, 6.000e+00],\n",
       "       [1.000e+00, 1.000e+00, 1.456e+03, 2.000e+00, 6.800e+00],\n",
       "       [1.000e+00, 1.000e+00, 1.760e+03, 1.000e+00, 7.100e+00],\n",
       "       [1.000e+00, 0.000e+00, 2.400e+03, 4.000e+00, 7.900e+00],\n",
       "       [1.000e+00, 0.000e+00, 2.148e+03, 3.000e+00, 8.200e+00],\n",
       "       [1.000e+00, 0.000e+00, 1.450e+03, 2.000e+00, 8.700e+00],\n",
       "       [1.000e+00, 0.000e+00, 1.000e+03, 4.000e+00, 9.000e+00],\n",
       "       [1.000e+00, 1.000e+00, 1.540e+03, 3.000e+00, 9.500e+00],\n",
       "       [1.000e+00, 0.000e+00, 1.500e+03, 2.000e+00, 9.600e+00],\n",
       "       [1.000e+00, 1.000e+00, 3.000e+03, 4.000e+00, 1.030e+01],\n",
       "       [1.000e+00, 0.000e+00, 2.100e+03, 3.000e+00, 1.050e+01]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = X[:,[0,1,3,4,5]]\n",
    "X_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again fit our model after removing 2nd column which was a dummy variable column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.961</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.954</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   152.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 03 Mar 2019</td> <th>  Prob (F-statistic):</th> <td>3.54e-17</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:13:08</td>     <th>  Log-Likelihood:    </th> <td> -300.09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    30</td>      <th>  AIC:               </th> <td>   610.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    25</td>      <th>  BIC:               </th> <td>   617.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 2.151e+04</td> <td> 4315.092</td> <td>    4.986</td> <td> 0.000</td> <td> 1.26e+04</td> <td> 3.04e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>-1466.4735</td> <td> 2285.214</td> <td>   -0.642</td> <td> 0.527</td> <td>-6172.961</td> <td> 3240.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    3.3230</td> <td>    2.331</td> <td>    1.426</td> <td> 0.166</td> <td>   -1.477</td> <td>    8.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td> -422.1845</td> <td> 1255.570</td> <td>   -0.336</td> <td> 0.739</td> <td>-3008.079</td> <td> 2163.710</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td> 9439.2110</td> <td>  497.467</td> <td>   18.975</td> <td> 0.000</td> <td> 8414.659</td> <td> 1.05e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.056</td> <th>  Durbin-Watson:     </th> <td>   1.918</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.358</td> <th>  Jarque-Bera (JB):  </th> <td>   1.630</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.407</td> <th>  Prob(JB):          </th> <td>   0.443</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.200</td> <th>  Cond. No.          </th> <td>7.20e+03</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.961\n",
       "Model:                            OLS   Adj. R-squared:                  0.954\n",
       "Method:                 Least Squares   F-statistic:                     152.6\n",
       "Date:                Sun, 03 Mar 2019   Prob (F-statistic):           3.54e-17\n",
       "Time:                        16:13:08   Log-Likelihood:                -300.09\n",
       "No. Observations:                  30   AIC:                             610.2\n",
       "Df Residuals:                      25   BIC:                             617.2\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       2.151e+04   4315.092      4.986      0.000    1.26e+04    3.04e+04\n",
       "x1         -1466.4735   2285.214     -0.642      0.527   -6172.961    3240.014\n",
       "x2             3.3230      2.331      1.426      0.166      -1.477       8.124\n",
       "x3          -422.1845   1255.570     -0.336      0.739   -3008.079    2163.710\n",
       "x4          9439.2110    497.467     18.975      0.000    8414.659    1.05e+04\n",
       "==============================================================================\n",
       "Omnibus:                        2.056   Durbin-Watson:                   1.918\n",
       "Prob(Omnibus):                  0.358   Jarque-Bera (JB):                1.630\n",
       "Skew:                           0.407   Prob(JB):                        0.443\n",
       "Kurtosis:                       2.200   Cond. No.                     7.20e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 7.2e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Value for x3 is highest i.e. 0.739 hence we will remove it. \n",
    "This means, x3 column, which was number of certifications done, was not having significant impact on salary prediction.\n",
    "\n",
    "Execute below line to remove x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.000e+00, 0.000e+00, 2.300e+03, 1.100e+00],\n",
       "       [1.000e+00, 1.000e+00, 2.100e+03, 1.300e+00],\n",
       "       [1.000e+00, 0.000e+00, 2.104e+03, 1.500e+00],\n",
       "       [1.000e+00, 0.000e+00, 1.200e+03, 2.000e+00],\n",
       "       [1.000e+00, 1.000e+00, 1.254e+03, 2.200e+00],\n",
       "       [1.000e+00, 0.000e+00, 1.236e+03, 2.900e+00],\n",
       "       [1.000e+00, 0.000e+00, 1.452e+03, 3.000e+00],\n",
       "       [1.000e+00, 1.000e+00, 1.789e+03, 3.200e+00],\n",
       "       [1.000e+00, 0.000e+00, 1.645e+03, 3.200e+00],\n",
       "       [1.000e+00, 0.000e+00, 1.258e+03, 3.700e+00],\n",
       "       [1.000e+00, 1.000e+00, 1.478e+03, 3.900e+00],\n",
       "       [1.000e+00, 0.000e+00, 1.257e+03, 4.000e+00],\n",
       "       [1.000e+00, 0.000e+00, 1.596e+03, 4.000e+00],\n",
       "       [1.000e+00, 1.000e+00, 1.256e+03, 4.100e+00],\n",
       "       [1.000e+00, 0.000e+00, 1.489e+03, 4.500e+00],\n",
       "       [1.000e+00, 0.000e+00, 1.236e+03, 4.900e+00],\n",
       "       [1.000e+00, 1.000e+00, 2.311e+03, 5.100e+00],\n",
       "       [1.000e+00, 0.000e+00, 2.245e+03, 5.300e+00],\n",
       "       [1.000e+00, 0.000e+00, 2.365e+03, 5.900e+00],\n",
       "       [1.000e+00, 0.000e+00, 1.500e+03, 6.000e+00],\n",
       "       [1.000e+00, 1.000e+00, 1.456e+03, 6.800e+00],\n",
       "       [1.000e+00, 1.000e+00, 1.760e+03, 7.100e+00],\n",
       "       [1.000e+00, 0.000e+00, 2.400e+03, 7.900e+00],\n",
       "       [1.000e+00, 0.000e+00, 2.148e+03, 8.200e+00],\n",
       "       [1.000e+00, 0.000e+00, 1.450e+03, 8.700e+00],\n",
       "       [1.000e+00, 0.000e+00, 1.000e+03, 9.000e+00],\n",
       "       [1.000e+00, 1.000e+00, 1.540e+03, 9.500e+00],\n",
       "       [1.000e+00, 0.000e+00, 1.500e+03, 9.600e+00],\n",
       "       [1.000e+00, 1.000e+00, 3.000e+03, 1.030e+01],\n",
       "       [1.000e+00, 0.000e+00, 2.100e+03, 1.050e+01]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = X[:,[0,1,3,5]]\n",
    "X_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.960</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.956</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   210.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 03 Mar 2019</td> <th>  Prob (F-statistic):</th> <td>2.35e-18</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:15:35</td>     <th>  Log-Likelihood:    </th> <td> -300.16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    30</td>      <th>  AIC:               </th> <td>   608.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    26</td>      <th>  BIC:               </th> <td>   613.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 2.122e+04</td> <td> 4154.694</td> <td>    5.108</td> <td> 0.000</td> <td> 1.27e+04</td> <td> 2.98e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>-1479.8541</td> <td> 2245.558</td> <td>   -0.659</td> <td> 0.516</td> <td>-6095.665</td> <td> 3135.956</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    3.3059</td> <td>    2.290</td> <td>    1.443</td> <td> 0.161</td> <td>   -1.402</td> <td>    8.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td> 9336.1224</td> <td>  385.024</td> <td>   24.248</td> <td> 0.000</td> <td> 8544.694</td> <td> 1.01e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.340</td> <th>  Durbin-Watson:     </th> <td>   1.842</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.310</td> <th>  Jarque-Bera (JB):  </th> <td>   1.662</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.375</td> <th>  Prob(JB):          </th> <td>   0.436</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.124</td> <th>  Cond. No.          </th> <td>7.04e+03</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.960\n",
       "Model:                            OLS   Adj. R-squared:                  0.956\n",
       "Method:                 Least Squares   F-statistic:                     210.7\n",
       "Date:                Sun, 03 Mar 2019   Prob (F-statistic):           2.35e-18\n",
       "Time:                        16:15:35   Log-Likelihood:                -300.16\n",
       "No. Observations:                  30   AIC:                             608.3\n",
       "Df Residuals:                      26   BIC:                             613.9\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       2.122e+04   4154.694      5.108      0.000    1.27e+04    2.98e+04\n",
       "x1         -1479.8541   2245.558     -0.659      0.516   -6095.665    3135.956\n",
       "x2             3.3059      2.290      1.443      0.161      -1.402       8.014\n",
       "x3          9336.1224    385.024     24.248      0.000    8544.694    1.01e+04\n",
       "==============================================================================\n",
       "Omnibus:                        2.340   Durbin-Watson:                   1.842\n",
       "Prob(Omnibus):                  0.310   Jarque-Bera (JB):                1.662\n",
       "Skew:                           0.375   Prob(JB):                        0.436\n",
       "Kurtosis:                       2.124   Cond. No.                     7.04e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 7.04e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, here p value of x1 i.e. another dummy variable from our perspective is 0.516 which needs to be removed. So our X_opt should be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.000e+00, 2.300e+03, 1.100e+00],\n",
       "       [1.000e+00, 2.100e+03, 1.300e+00],\n",
       "       [1.000e+00, 2.104e+03, 1.500e+00],\n",
       "       [1.000e+00, 1.200e+03, 2.000e+00],\n",
       "       [1.000e+00, 1.254e+03, 2.200e+00],\n",
       "       [1.000e+00, 1.236e+03, 2.900e+00],\n",
       "       [1.000e+00, 1.452e+03, 3.000e+00],\n",
       "       [1.000e+00, 1.789e+03, 3.200e+00],\n",
       "       [1.000e+00, 1.645e+03, 3.200e+00],\n",
       "       [1.000e+00, 1.258e+03, 3.700e+00],\n",
       "       [1.000e+00, 1.478e+03, 3.900e+00],\n",
       "       [1.000e+00, 1.257e+03, 4.000e+00],\n",
       "       [1.000e+00, 1.596e+03, 4.000e+00],\n",
       "       [1.000e+00, 1.256e+03, 4.100e+00],\n",
       "       [1.000e+00, 1.489e+03, 4.500e+00],\n",
       "       [1.000e+00, 1.236e+03, 4.900e+00],\n",
       "       [1.000e+00, 2.311e+03, 5.100e+00],\n",
       "       [1.000e+00, 2.245e+03, 5.300e+00],\n",
       "       [1.000e+00, 2.365e+03, 5.900e+00],\n",
       "       [1.000e+00, 1.500e+03, 6.000e+00],\n",
       "       [1.000e+00, 1.456e+03, 6.800e+00],\n",
       "       [1.000e+00, 1.760e+03, 7.100e+00],\n",
       "       [1.000e+00, 2.400e+03, 7.900e+00],\n",
       "       [1.000e+00, 2.148e+03, 8.200e+00],\n",
       "       [1.000e+00, 1.450e+03, 8.700e+00],\n",
       "       [1.000e+00, 1.000e+03, 9.000e+00],\n",
       "       [1.000e+00, 1.540e+03, 9.500e+00],\n",
       "       [1.000e+00, 1.500e+03, 9.600e+00],\n",
       "       [1.000e+00, 3.000e+03, 1.030e+01],\n",
       "       [1.000e+00, 2.100e+03, 1.050e+01]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = X[:,[0,3,5]]\n",
    "X_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.960</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.957</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   322.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 03 Mar 2019</td> <th>  Prob (F-statistic):</th> <td>1.42e-19</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:18:13</td>     <th>  Log-Likelihood:    </th> <td> -300.41</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    30</td>      <th>  AIC:               </th> <td>   606.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    27</td>      <th>  BIC:               </th> <td>   611.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 2.102e+04</td> <td> 4099.682</td> <td>    5.127</td> <td> 0.000</td> <td> 1.26e+04</td> <td> 2.94e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    3.1236</td> <td>    2.250</td> <td>    1.389</td> <td> 0.176</td> <td>   -1.492</td> <td>    7.739</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td> 9340.2046</td> <td>  380.920</td> <td>   24.520</td> <td> 0.000</td> <td> 8558.621</td> <td> 1.01e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.451</td> <th>  Durbin-Watson:     </th> <td>   1.842</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.484</td> <th>  Jarque-Bera (JB):  </th> <td>   1.323</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.388</td> <th>  Prob(JB):          </th> <td>   0.516</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.325</td> <th>  Cond. No.          </th> <td>7.01e+03</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.960\n",
       "Model:                            OLS   Adj. R-squared:                  0.957\n",
       "Method:                 Least Squares   F-statistic:                     322.5\n",
       "Date:                Sun, 03 Mar 2019   Prob (F-statistic):           1.42e-19\n",
       "Time:                        16:18:13   Log-Likelihood:                -300.41\n",
       "No. Observations:                  30   AIC:                             606.8\n",
       "Df Residuals:                      27   BIC:                             611.0\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       2.102e+04   4099.682      5.127      0.000    1.26e+04    2.94e+04\n",
       "x1             3.1236      2.250      1.389      0.176      -1.492       7.739\n",
       "x2          9340.2046    380.920     24.520      0.000    8558.621    1.01e+04\n",
       "==============================================================================\n",
       "Omnibus:                        1.451   Durbin-Watson:                   1.842\n",
       "Prob(Omnibus):                  0.484   Jarque-Bera (JB):                1.323\n",
       "Skew:                           0.388   Prob(JB):                        0.516\n",
       "Kurtosis:                       2.325   Cond. No.                     7.01e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 7.01e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now remove x1 column which represents our worked hours, p values is coming as 0.176 which is way over our significance level 0.05 hence we can remove x1 i.e. worked hours column too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_opt = X[:,[0,5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we now have only two columns left and if you closely watch p values for const and x2 in above p value table, they are 0.000 which are below significance level 0.05.\n",
    "- It means they are important and have impact on salary predictions. \n",
    "- So our backward elimination for multiple linear regression is now stopped. \n",
    "- We will predict salaries based on current state of X_opt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict salaries for X_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_opt_train, X_opt_test, y_opt_train, y_opt_test = train_test_split(X_opt, y, test_size = 1/3, random_state = 0)\n",
    "regressor_opt = LinearRegression()\n",
    "regressor_opt.fit(X_opt_train, y_opt_train)\n",
    " \n",
    "y_opt_pred = regressor_opt.predict(X_opt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 40835.10590871, 123079.39940819,  65134.55626083,  63265.36777221,\n",
       "       115602.64545369, 108125.8914992 , 116537.23969801,  64199.96201652,\n",
       "        76349.68719258, 100649.1375447 ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_opt_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predictions obtained from backward elimination for multiple linear regression are much closer to actual results and same as simple linear regression in our case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
